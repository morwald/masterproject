%-------------------------------------------------------------------------------
% IMPLEMENTATION ASPECTS
%-------------------------------------------------------------------------------

\section{Implementation Aspects} \label{sec:impl}

\subsection{The Julia Programming Language}

Another important aspect of this work is the implementation using the
open-source programming language Julia \citep{bezanson2017}. This programming
language is designed for high-performance computing. It is a dynamically typed
language but compiles efficient code via LLVM. The LLVM compiler infrastructure
gives a code language-intermediated representation that is
platform-independent. Julia offers performance comparable to compiled code of
statically typed languages such as C or Fortran.

Another important feature is the use of the multiple dispatch paradigm. This
paradigm allows a function to be dynamically dispatched based on the run-time
information of the function's arguments. Then, once a function has been
compiled for a set of input types, the successive call of the function will not
have to be recompiled and will give the expected performance. The compiler
chooses the appropriate dispatch based on the input types, hence the name
multiple dispatch.

For the regularized four-sided cavity flow, the Group of Nonlinear Fluid
Dynamics at UPC has developed a MATLAB code implementing some of the necessary
algorithms for solving this problem. This project has dealt with the
translation and extension of the already existing code. The developed Julia
model aims to be a simple open-source example of the proposed problem. This
section will skip many details but highlight some optimization and design
choices for the implementation.

\subsection{Implementation of the Nonlinear Function}

Julia provides a way to develop the code similar to scripting languages such as
Python, but then one can add optimizations where needed without changing the
language. This coding style will be demonstrated by showing the implementation
of the nonlinear function. 

We want to recall the dynamical system defined in equations \eqref{eq:dyn_sys}.
The code of this nonlinear function $F(\Psi, Re)$ has to be highly optimized,
as it is evaluated in a very Newton-Raphson iteration multiple times. The most
costly part consists of calculating the Jacobian where the function is called
of the order $\mathcal{O}(m^2)$.

The following code snippet shows a straightforward implementation of the
nonlinear function. 

\begin{jllisting}[caption=Simple implementation in Julia of the nonlinear
  function $F$ \vspace{4pt},float]
function f(u, p::CavityStruct)
    @unpack Re, n, D1, D2, D4 = p

    Ψ = constructBC(u, p)

    biharmΨ = D4*Ψ +  Ψ*D4' + 2*(D2*Ψ)*D2'
    laplΨ = D2*Ψ + Ψ*D2'
    nonlinterm = (D1*Ψ).*(laplΨ*D1') - (D1*laplΨ).*(Ψ*D1')
    
    fΨ = 1/Re*biharmΨ - nonlinterm
    fu = fΨ[3:(n - 1), 3:(n - 1)][:]

    return fu 
end
\end{jllisting}

In the above, the input vector \jlinl{u} corresponds to the inner elements of
the streamfunction. The second input \jlinl{p} is a \jlinl{struct} containing
the necessary parameters and the differentiation matrices. 

The coding style of defining a nonlinear function of a differential equation as
\jlinl{f(u,p)} is widely used in the Julia ecosystem. This standard helps to
easily pass the function to other libraries to compute the Jacobian, for
example. Moreover, one can use Unicode input such as the $\Psi $ symbol to
facilitate the notations for mathematical expressions. The
\jlinl{constructBC(u,p)} is a function (see appendix), which returns the
streamfunction matrix by constructing the two outer rows and columns from the
given boundary conditions to the vector \jlinl{u}.

Though this function could be more efficient. If we want to use it repeatedly,
every function call will allocate a new variable for the matrices. A useful
approach is to pre-allocate memory which we pass to the function and reuse at
every function call. The optimized, allocation-free version is shown in the
second code snippet. 

\begin{jllisting}[caption=Optimized implementation in Julia of the nonlinear
  function $F$ \vspace{4pt},float]
function f!(fu, u, p::CavityStruct)
    @unpack Re, n, D1, D2, D4 = p.params
    @unpack fΨ, Ψ, D2Ψ, ΨD2, D4Ψ, ΨD4, laplΨ, biharmΨ = p.cache

    @inbounds @views Ψ[3:(n - 1), 3:(n - 1)][:] .= u

    constructBC!(Ψ, p)

    mul!(D4Ψ, D4, Ψ)
    mul!(ΨD4, Ψ, D4')

    mul!(D2Ψ, D2, Ψ)
    mul!(ΨD2, Ψ, D2')

    mul!(laplΨ, D2Ψ, D2') # using as intermediate memory
    @inbounds @. biharmΨ = D4Ψ + ΨD4 + 2 * laplΨ
    @inbounds @. laplΨ = D2Ψ + ΨD2

    mul!(D2Ψ, D1, Ψ)
    mul!(ΨD2, Ψ, D1')

    mul!(ΨD4, laplΨ, D1')
    mul!(D4Ψ, D1, laplΨ)

    @inbounds @. laplΨ = D2Ψ * ΨD4 - D4Ψ * ΨD2
    @inbounds @. fΨ = (1 / Re) * biharmΨ + laplΨ

    @inbounds @views fu .= fΨ[3:(n - 1), 3:(n - 1)][:]

    return nothing
end
\end{jllisting}

The exclamation mark in front of the \jlinl{f} in the function definition is
standard to inform the programmer that the function is changing its input
variable (here \jlinl{fu}). \jlinl{f!(fu, u, p)} is then referred to as an
in-place function. In general, this cache-like programming style is important
when writing efficient Julia code.
In the optimized version, the \jlinl{struct
p} is now split into two sub- \jlinl{struct}s containing the parameters and
cache variables. The cache variables are reused to store the intermediate
results. The \jlinl{mul!(C, A, B)} function does a matrix multiplication, $AB$,
and stores the values in C without allocating a new variable. Secondly, a dot
(\jlinl{.}) before an operation applies an element-wise operation, and the
macro denoted by an \jlinl{@.} will apply it to all the operations of an
expression. The \jlinl{@inbounds} macro turns off bound checking (consumes time
as well) and should be used carefully.

A bottleneck in this implementation is that representation is changed from
\jlinl{u} to \jlinl{Ψ} and vis versa in every function call. The vector
\jlinl{u} accesses the inner elements of the streamfunction matrix \jlinl{Ψ}.
This access is not aligned in memory, making it slower operation. \\

Below is a list of the implemented algorithms in Julia, which are only
implemented for square domains with $(m+1) \times (m+1)$ grid points:

\begin{itemize}
  \item Newton-Rapshon (Jacobian construction through \emph{FinitDiff.jl}),
    absolute tolerance set to $10^{-10}$
  \item Time-stepping with an implicit Euler scheme
  \item Pseudo-arclength continuation, and saving results to a CSV file
  \item Linear stability analysis, by use of the \jlinl{eigen}-function of the
    Julia base library \emph{LinearAlgebra.jl}
\end{itemize}

The functions are implemented in a Julia module named
\emph{FourSidedCavityFlow.jl}, which will be available on GitHub. Finally, it
has to be mentioned that there exists a package for Julia called
\emph{BifurcationKit.jl} \citep{veltz2020}. This module provides parameter
continuation for a given nonlinear problem, a Newton-Krylov (matrix-free)
solver and forward mode automatic differentiation. This is indispensable in
large problems. However, the Newton-Raphson and an explicitly constructed
Jacobian work best for the four-sided cavity and through regularization, the
successful convergence of the spectral discretizations does not need too many
grid points.

\subsection{Comparison between MATLAB and Julia}

Table \ref{tab:comp} provides a comparison between some basic operations for
the R4CF implemented in Julia and MATLAB. The benchmark was performed on an
Intel Core i5-5200U processor.

The table shows a slight decrease in time using the Julia module. One might
expect that the Julia code should be much faster, but the problem here is that
most of the time is spent doing matrix multiplication, where MATLAB is highly
optimized, and essentially both implementations will run the same lower level
\emph{Blas} (Basic Linear Algebra Subprograms) routines. Still, as the
Newton-Raphson method will be called repeatedly in the continuation algorithm,
this performance gain can add up quickly. Nonetheless, this cache-like
programming style in Julia is indispensable to achieve a similar efficiency as
in MATLAB, but one has to do these kinds of optimizations only for specific
functions where efficiency matters.


\begin{table}[ht]
  \caption{MATLAB vs. Julia comparison of median time to solve for a steady
    state solution at Reynolds number 100 (MATLAB: \jlinl{timeit}, Julia:
    \jlinl{@benchmark})}.
  \label{tab:matlab_julia}
\begin{tabular}{lrrr}
Test & $m$ & MATLAB time (ms) & Julia time (ms) \\
\hline
Function evaluation  & $32$ & $0.0949$  & $0.0526$ \\
& $64$ & $0.3267$ & $0.2232$ \\
 Creating the Jacobian  & $32$ & $83.6$  &  $49.5$  \\
& $64$ & $1152.6$ & $858.3$ \\
Newton (3 iterations)  & $32$ & $196.7$ & $126.7$ \\
& $64$ & $5861$  & $4878$ \\
\label{tab:comp}
\end{tabular}
\end{table}
